{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes 朴素贝叶斯法\n",
    "### It's a way to find the probability of an event using the probability of other events\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "朴素贝叶斯法(Naive Bayes)是基于贝叶斯定理和特征条件独立假设的分类方法。\n",
    "对于给定的训练集，基于特征条件独立的假设学习输入和输出的联合概率；通过此模型，对于给定的输入x，计算后验概率(MAP)最大的输出y作为预测分类结果。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "首先这里直接给出Naive Bayes算法的核心公式：\n",
    "$$P(Y|X) = \\frac{P(Y)P(X|Y)}{P(X)}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在这个公式中，    \n",
    "`P(Y|X)`: **posterior**, the probability of Y being TRUE giving that X is TRUE.    \n",
    "`P(Y)`: **prior**, the probability of Y being TRUE.    \n",
    "`P(X|Y)`: **likelihood**, the probability of X being TRUE giving that Y is TRUE.    \n",
    "`P(X)`: **evidence**, the probability of X being TRUE.    \n",
    "\n",
    "最后通过这个公式的计算，我们选取可以使得`P(Y|X)`值最大的`Y`作为预测结果。这种预测方式叫做Maximum a-posterior(MAP) hypothesis，即最大后验概率。    \n",
    "需要注意的是，对于`Y`的预测取决于`P(Y|X)`的大小，由公式可见所有预测的分母均相同，为`P(X)`，所以它并不会对预测产生影响，其作用是为了normalize所有可能性的概率。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这里通过一个例子来具体讲解一下Naive Bayes算法的过程。    \n",
    "\n",
    "#### 例1：\n",
    "我们给定如下一个数据集，输入空间由三个特征向量X1，X2和X3组成，输出为Label = {+, -}。 \n",
    "其中,    \n",
    "`X1 = {Low, Medium, High}`    \n",
    "`X2 = {Yes, No}`    \n",
    "`X3 = {Red, Green}`    \n",
    "最后，请问`{Low, Yes, Green}`相应的Label是什么？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| X1 | X2 | X3 | Label |\n",
    "| :-: | :-: | :-: | :-: |\n",
    "| Low | No | Red | + |\n",
    "| Medium | No | Green | + |\n",
    "| Low | No | Green | + |\n",
    "| Low | Yes | Red | - |\n",
    "| High | No | Green | - |\n",
    "| Medium | Yes | Green | - |\n",
    "| High | Yes | Green | - |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 解1：\n",
    "首先，由Naive Bayes公式可知，我们需要做的是：    \n",
    "比较`P(Label = + | X1 = Low, X2 = Yes, X3 = Green)`和`P(Label = - | X1 = Low, X2 = Yes, X3 = Green)`的大小。    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来，我们由对应的特征向量分析数据集：   \n",
    "`P(Label = +) = 3 / 7`    \n",
    "`P(Label = -) = 4 / 7`    \n",
    "`P(X1 = Low   | Label = +) = 2/3`    \n",
    "`P(X2 = Yes   | Label = +) = 0/3`    \n",
    "`P(X3 = Green | Label = +) = 2/3`    \n",
    "`P(X1 = Low   | Label = -) = 1/4`    \n",
    "`P(X2 = Yes   | Label = -) = 3/4`    \n",
    "`P(X3 = Green | Label = -) = 3/4`    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有了以上的结果之后，就可以进行最后结果的运算了：     \n",
    "\n",
    "首先，算出：    \n",
    "$$P(X1 = Low, X2 = Yes, X3 = Green | Label = +) = P(X1 = Low   | Label = +) · P(X2 = Yes   | Label = +) · P(X3 = Green | Label = +) \\\\= \\frac{2}{3} · \\frac{0}{3} · \\frac{2}{3} = 0$$    \n",
    "$$P(X1 = Low, X2 = Yes, X3 = Green | Label = -) = P(X1 = Low   | Label = -) · P(X2 = Yes   | Label = -) · P(X3 = Green | Label = -) \\\\= \\frac{1}{4} · \\frac{3}{4} · \\frac{3}{4} = \\frac{9}{64}$$    \n",
    "对于：    \n",
    "$$P(Label = + | X1 = Low, X2 = Yes, X3 = Green) = \\frac{P(Label = +)·P(X1 = Low, X2 = Yes, X3 = Green | Label = +)}{P(X1 = Low, X2 = Yes, X3 = Green)} $$   \n",
    "\n",
    "\n",
    "之前已经解释过分母对预测结果不产生影响，所以：  \n",
    "$$P(Label = + | X1 = Low, X2 = Yes, X3 = Green) = P(Label = +)·P(X1 = Low, X2 = Yes, X3 = Green | Label = +) \\\\= \\frac{3}{7} · 0 = 0$$    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "同理：    \n",
    "$$P(Label = - | X1 = Low, X2 = Yes, X3 = Green) = P(Label = -)·P(X1 = Low, X2 = Yes, X3 = Green | Label = +) \\\\= \\frac{4}{7} · \\frac{9}{64} = 0.08035714286$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "通过比较，由于`P(Label = - | X1 = Low, X2 = Yes, X3 = Green)`更大，所以Naive Bayes法对于此数据的预测为`Label = - `。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "以上，便是朴素贝叶斯算法的实际运用方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Follow Up\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Smoothing 平滑处理\n",
    "\n",
    "从上面的例子，可以注意到在计算Label为+的情况时，由于`P(X2 = Yes | Label = +)`的概率为0从而使得整个特征空间出现的概率都为0。这种情况在实际运用中是会对预测结果产生影响的。那么该如何避免呢？"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "为了避免出现该情况，需要对条件概率公式进行如下平滑处理：\n",
    "$$P_\\lambda(Y=c_k) = \\frac{\\sum_{i=1}^{N}{I(y_i = c_k)}+ \\lambda}{N + K \\lambda}$$    \n",
    "在这个公式中，     \n",
    "$$P_\\lambda(Y=c_k): Y=c_k出现的概率$$\n",
    "$$\\sum_{i=1}^{N}{I(y_i = c_k)}: Y=c_k出现的次数$$\n",
    "$$\\lambda: 平滑常数，当\\lambda = 1时，称为拉普拉斯平滑(Laplacian Smoothing)$$\n",
    "$$N: Y的总数$$\n",
    "$$K: Y的类别数$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由此，取**平滑常数为1**，更新**例1**变为：\n",
    "$$P(Label = +) = \\frac{3 + 1}{7 + 2 * 1} = \\frac{4}{9}$$    \n",
    "$$P(Label = -) = \\frac{4 + 1}{7 + 2 * 1} = \\frac{5}{9}$$    \n",
    "$$P(X1 = Low | Label = +) = \\frac{2 + 1}{3 + 3 * 1} = \\frac{1}{2}$$    \n",
    "$$P(X2 = Yes | Label = +) = \\frac{0 + 1}{3 + 2 * 1} = \\frac{1}{5}$$    \n",
    "$$P(X3 = Green | Label = +) = \\frac{2 + 1}{3 + 2 * 1} = \\frac{3}{5}$$   \n",
    "$$P(X1 = Low | Label = -) = \\frac{1 + 1}{4 + 3 * 1} = \\frac{2}{7}$$    \n",
    "$$P(X2 = Yes | Label = -) = \\frac{3 + 1}{4 + 2 * 1} = \\frac{2}{3}$$    \n",
    "$$P(X3 = Green | Label = -) = \\frac{3 + 1}{4 + 2 * 1} = \\frac{2}{3}$$   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后，计算：    \n",
    "$$P(X1 = Low, X2 = Yes, X3 = Green | Label = +) = P(X1 = Low   | Label = +) · P(X2 = Yes   | Label = +) · P(X3 = Green | Label = +) \\\\= \\frac{1}{2} · \\frac{1}{5} · \\frac{3}{5} = \\frac{3}{50}$$    \n",
    "$$P(X1 = Low, X2 = Yes, X3 = Green | Label = -) = P(X1 = Low   | Label = -) · P(X2 = Yes   | Label = -) · P(X3 = Green | Label = -) \\\\= \\frac{2}{7} · \\frac{2}{3} · \\frac{2}{3} = \\frac{6}{63}$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(Label = + | X1 = Low, X2 = Yes, X3 = Green) = P(Label = +)·P(X1 = Low, X2 = Yes, X3 = Green | Label = +) \\\\= \\frac{4}{9} · \\frac{3}{50} = 0.02666666667$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(Label = - | X1 = Low, X2 = Yes, X3 = Green) = P(Label = -)·P(X1 = Low, X2 = Yes, X3 = Green | Label = +) \\\\= \\frac{5}{9} · \\frac{6}{63} = 0.05291005291$$    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最后通过比较，预测`Label`依旧为`-`。\n",
    "以上，便是使用了拉普拉斯平滑处理之后的朴素贝叶斯方法。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 朴素贝叶斯法 - 垃圾邮件检测模型"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这个模型的目的是检测一个邮件是为垃圾邮件还是正常邮件。主要的思想为通过对邮件里每个单词出现在垃圾邮件和正常邮件里的概率从而计算出由这些单词组成的邮件是否为垃圾邮件。    \n",
    "数据集来自UCI机器学习项目，可以从此处下载：https://archive.ics.uci.edu/ml/datasets/SMS+Spam+Collection."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 1:  Getting, understanding, and cleaning the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>ham</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>ham</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>spam</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>ham</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>ham</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                        sms_message\n",
       "0   ham  Go until jurong point, crazy.. Available only ...\n",
       "1   ham                      Ok lar... Joking wif u oni...\n",
       "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3   ham  U dun say so early hor... U c already then say...\n",
       "4   ham  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_table('SMSSpamCollection', sep = '\\t', header = None, names = ['label', 'sms_message'])\n",
    "\n",
    "# Lets observe the first 5 rows of data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Preproccessing\n",
    "为了方便处理，我们将垃圾邮件(spam)的label设为1， 将正常邮件(ham)设为0。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>sms_message</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                        sms_message\n",
       "0      0  Go until jurong point, crazy.. Available only ...\n",
       "1      0                      Ok lar... Joking wif u oni...\n",
       "2      1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3      0  U dun say so early hor... U c already then say...\n",
       "4      0  Nah I don't think he goes to usf, he lives aro..."
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['label'] = df.label.map({'spam': 1, 'ham': 0})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "接下来， 将数据集分开，一部分作为训练集，一部分作为测试集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train_msgs, df_test_msgs, df_ytrain, df_ytest = train_test_split(df['sms_message'],df['label'], random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "然后对邮件本身进行一下处理，将每一封邮件处理为一个特征向量。需要一个feature来储存目前出现的单词（相当于一个字典），对于一封邮件，如果这个词出现在其中了，那么在这个feature中这个单词对应的值便为1，反之为0。     \n",
    "\n",
    "举个例子，假设我们的字典里有[thank, good, night, apple, banana, river]，然后手里的邮件为：“banana river”， 那么这个邮件便表示为[0, 0, 0, 0, 1, 1]。\n",
    "\n",
    "为了达到这个目的，需要使用Sklearn库中的CounterVectorize方法。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# stop_words words that will not help us predict since they occur in most documents,\n",
    "# e.g. 'a', 'and', 'the', 'him', 'is' ...\n",
    "# Run：print(vectorizer.get_stop_words()) to see stop_word\n",
    "vectorizer = CountVectorizer(binary = True, stop_words='english')\n",
    "\n",
    "# Create the vocabulary for our feature transformation\n",
    "vectorizer.fit(df_train_msgs)\n",
    "\n",
    "# Next we create the feature vectors for both the training data and the test data\n",
    "X_train = vectorizer.transform(df_train_msgs).toarray() # code to turn the training emails into a feature vector\n",
    "X_test = vectorizer.transform(df_test_msgs).toarray() # code to turn the test email into a feature vector\n",
    "\n",
    "# Changing the target vectors data type  \n",
    "y_train=df_ytrain.to_numpy() # Convereting from a Panda series to a numpy array\n",
    "y_test = df_ytest.to_numpy()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 2: Implementing the algorithm and training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The estimated value of P(y) for y = 0 (ham): 0.8655180665230916\n",
      "The estimated value of P(y) for y = 1 (spam): 0.13448193347690834\n"
     ]
    }
   ],
   "source": [
    "# count for ham and spam message:\n",
    "ham_count = float(np.sum(y_train == 0))\n",
    "spam_count = float(np.sum(y_train == 1))\n",
    "\n",
    "# calculate the estimated value of P(y) for each class y.\n",
    "p_y0 = ham_count/y_train.size\n",
    "p_y1 = spam_count/y_train.size\n",
    "\n",
    "print(\"The estimated value of P(y) for y = 0 (ham): {}\".format(p_y0))\n",
    "print(\"The estimated value of P(y) for y = 1 (spam): {}\".format(p_y1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Smoothing lambda value\n",
    "m = 1\n",
    "\n",
    "bern_matrix_y0 = np.array([0 for _ in range(X_train[0].size)]) # class 0 -- ham\n",
    "bern_matrix_y1 = np.array([0 for _ in range(X_train[0].size)]) # class 1 -- spam\n",
    "# the number of occurrences of each word\n",
    "for i, msg in enumerate(X_train):\n",
    "    if y_train[i] == 0:\n",
    "        bern_matrix_y0 += msg\n",
    "    else:\n",
    "        bern_matrix_y1 += msg\n",
    "        \n",
    "bern_matrix_y0 = (bern_matrix_y0+m) / (ham_count+m*2)\n",
    "bern_matrix_y1 = (bern_matrix_y1+m) / (spam_count+m*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict the test dataset\n",
    "y_pre = []\n",
    "for i, msg in enumerate(X_test):\n",
    "    p_map0 = np.log(p_y0) # log(p(new email ∣ ham)p(ham))\n",
    "    p_map1 = np.log(p_y1) # log(p(new email ∣ spam)p(spam))\n",
    "    \n",
    "    for j, word in enumerate(msg):\n",
    "        if word == 1:\n",
    "            p_map0 += np.log(bern_matrix_y0[j])\n",
    "            p_map1 += np.log(bern_matrix_y1[j])\n",
    "        else:\n",
    "            p_map0 += np.log(1 - bern_matrix_y0[j])\n",
    "            p_map1 += np.log(1 - bern_matrix_y1[j])\n",
    "    y_pre.append(0) if p_map0 > p_map1 else y_pre.append(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of test examples classiﬁed correctly: 1362\n",
      "The accuracy on the test set: 0.9777458722182341\n"
     ]
    }
   ],
   "source": [
    "# The accuracy on test sets\n",
    "correct_num = 0\n",
    "for i, j in zip(y_test, y_pre):\n",
    "    correct_num = correct_num+(i==j)\n",
    "print(\"Total number of test examples classiﬁed correctly: {}\".format(correct_num))\n",
    "print(\"The accuracy on the test set: {}\".format(correct_num/y_test.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Step 3: Using build-in library\n",
    "其实Sklearn库里已经包含了Naive Bayes的实现方法，可以直接拿来用，方法如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BernoulliNB(alpha=1.0, binarize=0.0, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import metrics\n",
    "\n",
    "clf = BernoulliNB()\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "By using build in library, the accuracy is:  0.9777458722182341\n"
     ]
    }
   ],
   "source": [
    "y_pred = clf.predict(X_test)\n",
    "print(\"By using build in library, the accuracy is: \", metrics.accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "本文简单介绍了什么是朴素贝叶斯模型，应该如何使用，以及使用平滑（smoothing）的方法去解决0概率的问题。具体原理和公式的推导可以去看一下李航老师的《统计学习方法》一书。    \n",
    "这篇文章关于朴素贝叶斯模型其实只是运用了其中的多元伯努利模型，其实朴素贝叶斯模型还有列如多项式事件模型（Multinomial Naive Bayes）等其他的方法，如果感兴趣可以深入学习。    \n",
    "\n",
    "Thanks & Bye ~"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
